{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preperation**"
      ],
      "metadata": {
        "id": "lI50ApsoS5h4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Goals**\n",
        "## In this section, our objectives were to process the data received from the company's two clients to make it suitable for use in models. This involved several steps, including data cleaning, addressing missing values, adding necessary columns, removing unnecessary columns, and standardizing the data based on the provided Excel file from the company. Additionally, we created the urgency target variable and incorporated it into the dataset."
      ],
      "metadata": {
        "id": "uQ3wCBR_Ucwh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6Jkf3Oupjg1"
      },
      "outputs": [],
      "source": [
        "!pip install pandas\n",
        "import numpy as np\n",
        "from scipy.stats import skewnorm\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy import linspace\n",
        "from scipy import pi,sqrt,exp\n",
        "from scipy.special import erf\n",
        "from pylab import plot,show\n",
        "import random\n",
        "from sklearn.preprocessing import MinMaxScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgRBqmMtNhFt"
      },
      "outputs": [],
      "source": [
        "!pip install google.colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3BtilNpfaTU"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/d/MyDrive/final_project/Data_for_Urgency_Model.xlsx'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Standarization**"
      ],
      "metadata": {
        "id": "ocy6nb5kQyj1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BP7u8aO4nB13"
      },
      "outputs": [],
      "source": [
        "#standardisation of priority coulmn\n",
        "\n",
        "def standardize_priority(filepath):\n",
        "    \"\"\"Standardizes the values in the 'Priority' column of an Excel file.\n",
        "\n",
        "    Parameters:\n",
        "        filepath (str): The file path to the Excel file.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: The DataFrame with the 'Priority' column standardized.\n",
        "    \"\"\"\n",
        "\n",
        "    # Read the Excel file into a pandas DataFrame\n",
        "    df = pd.read_excel(filepath)\n",
        "\n",
        "\n",
        "    # Convert all values in the priority column to lowercase\n",
        "    df['Priority'] = df['Priority'].str.lower()\n",
        "\n",
        "\n",
        "    # Define the priority mapping dictionary\n",
        "    priority_map = {\n",
        "        1: ['stat'],\n",
        "        2: ['high'],\n",
        "        3: ['routine']\n",
        "    }\n",
        "\n",
        "\n",
        "    # Iterate through the priority mapping dictionary and replace values in the priority column with their corresponding priority\n",
        "    for priority, keywords in priority_map.items():\n",
        "        for keyword in keywords:\n",
        "            df['Priority'] = df['Priority'].replace(keyword, priority)\n",
        "\n",
        "\n",
        "    # Convert the values in the priority column to integers\n",
        "    df['Priority'] = pd.to_numeric(df['Priority'], errors='coerce')\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        "    # Read the Excel file into a pandas DataFrame\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    # Convert all values in the priority column to lowercase\n",
        "    df['Priority'] = df['Priority'].str.lower()\n",
        "\n",
        "    # Define the priority mapping dictionary\n",
        "    priority_map = {\n",
        "        1: ['stat'],\n",
        "        2: ['high'],\n",
        "        3: ['routine']\n",
        "    }\n",
        "\n",
        "    # Iterate through the priority mapping dictionary and replace values in the priority column with their corresponding priority\n",
        "    for priority, keywords in priority_map.items():\n",
        "        for keyword in keywords:\n",
        "            df['Priority'] = df['Priority'].replace(keyword, priority)\n",
        "\n",
        "    # Convert the values in the priority column to integers\n",
        "    df['Priority'] = pd.to_numeric(df['Priority'], errors='coerce')\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEZVNUzH_gZt"
      },
      "outputs": [],
      "source": [
        "df = standardize_priority(file_path)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dealing with Missing Values**"
      ],
      "metadata": {
        "id": "mXf78ASxRDYg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wt0OjgYyQORA"
      },
      "outputs": [],
      "source": [
        "#Fill the blanck values in the column 'Patient Class' with NaN\n",
        "df['Patient Class'].fillna(\" \")\n",
        "df['Patient Class']=df['Patient Class'].str.lower()\n",
        "df['Patient Class'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Exam Description'] = df['Exam Description'].fillna(\"unknown\")"
      ],
      "metadata": {
        "id": "kGLn6Xpl7ZCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Removing columns**"
      ],
      "metadata": {
        "id": "M3boPtXKRZSM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJjlf5tASHtJ"
      },
      "outputs": [],
      "source": [
        "#Deleting unnecessary columns\n",
        "def remove_columns(df, columns):\n",
        "  return df.drop(columns=columns)\n",
        "df=remove_columns(df, ['Exam Group', 'Referring Physician', 'Status', 'Ordered', 'First Image Acquired', 'Dictated', 'Transcribed', 'Reported', 'wRVU',\n",
        "                    'Number of Images', 'Study_Count_2022'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaOowXsStsvC"
      },
      "outputs": [],
      "source": [
        "file_path2 = '/content/d/MyDrive/final_project/Dictionary.xlsx'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Adding columns**"
      ],
      "metadata": {
        "id": "JNj7Z3-BRhvU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFJdRyRiuEuk"
      },
      "outputs": [],
      "source": [
        "#Creating \"Body part\" column\n",
        "def add_body_part_column(df, file_path2, sheet_name):\n",
        "    \"\"\"\n",
        "    Adds a 'body part' column to a DataFrame based on the values in an Excel file.\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas.DataFrame): The DataFrame to add the 'body part' column to.\n",
        "    file_path (str): The file path of the Excel file to read from.\n",
        "    sheet_name (str): The name of the sheet in the Excel file to read from.\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: The original DataFrame with the 'body part' column added.\n",
        "    \"\"\"\n",
        "    # Read Excel file into a pandas DataFrame\n",
        "    df_excel = pd.read_excel(file_path2, sheet_name=sheet_name)\n",
        "\n",
        "    # Create a dictionary to map \"Description contains\" to \"Body part\" values\n",
        "    sub_dict = {}\n",
        "    for index, row in df_excel.iterrows():\n",
        "        body_part = row['Body part']\n",
        "        desc_contains = row['Description contains']\n",
        "        sub_dict[desc_contains] = body_part\n",
        "\n",
        "    # Create 'body_part' column based on 'Exam Description'\n",
        "    body_part_list = []\n",
        "    for index, row in df.iterrows():\n",
        "        exam_desc = row['Exam Description']\n",
        "        body_part = 'UNKNOWN'\n",
        "        for desc_contains, part in sub_dict.items():\n",
        "            if desc_contains.lower() in exam_desc.lower():\n",
        "                body_part = part\n",
        "                break\n",
        "        body_part_list.append(body_part)\n",
        "\n",
        "    df['Body Part'] = body_part_list\n",
        "    df['Body Part'] = df['Body Part'].str.lower()\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTfa5PgZ3NlS"
      },
      "outputs": [],
      "source": [
        "df=add_body_part_column(df, file_path2, sheet_name='Description to body part')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqefvD218SS8"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVjJMZ6TS1em"
      },
      "outputs": [],
      "source": [
        "df['Modality'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Standartization**"
      ],
      "metadata": {
        "id": "2RAmr6ztRpG5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QELZE76OGhw"
      },
      "outputs": [],
      "source": [
        "#Creating standartization for \"Modality\" column\n",
        "import pandas as pd\n",
        "\n",
        "def standardize_modality(df, file_path2):\n",
        "    \"\"\"Standardizes the values in the 'Modality' column of a DataFrame using a dictionary of mappings.\n",
        "\n",
        "    Parameters:\n",
        "        df (pandas.DataFrame): The input DataFrame containing the 'Modality' column to be standardized.\n",
        "        file_path2 (str): The file path to the Excel file containing the dictionary of mappings.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: The DataFrame with the 'Modality' column standardized according to the dictionary of mappings.\n",
        "    \"\"\"\n",
        "    # Read the dictionary Excel file into a pandas DataFrame\n",
        "    dictionary_df = pd.read_excel(file_path2, sheet_name='Atlantic&Avera modality')\n",
        "\n",
        "    # Convert 'Atlantic&Avera Modality' and 'Modality new' columns to lowercase for case-insensitive matching\n",
        "    dictionary_df['Atlantic&Avera Modality'] = dictionary_df['Atlantic&Avera Modality'].str.lower()\n",
        "    dictionary_df['Modality new'] = dictionary_df['Modality new'].str.lower()\n",
        "\n",
        "    # Convert 'Modality' column in the input DataFrame to lowercase\n",
        "    df['Modality'] = df['Modality'].str.lower()\n",
        "\n",
        "    # Apply the standardisation to the 'Modality' column in the input DataFrame\n",
        "    for index, row in dictionary_df.iterrows():\n",
        "        old_value = row['Atlantic&Avera Modality']\n",
        "        new_value = row['Modality new']\n",
        "        for index, row in df.iterrows():\n",
        "          if row['Modality'] in old_value:\n",
        "            df.at[index, 'Modality'] = new_value\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZ4awjaFVXWB"
      },
      "outputs": [],
      "source": [
        "df=standardize_modality(df, file_path2)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "du0gXkzYr3cI"
      },
      "outputs": [],
      "source": [
        "df['Modality'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Adding columns**"
      ],
      "metadata": {
        "id": "ZtPvKQ1HRxDO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWkBRE4xXQZu"
      },
      "outputs": [],
      "source": [
        "# Adding a \"subspecialty\" column to the df\n",
        "# Read Excel file into a pandas DataFrame\n",
        "df_excel = pd.read_excel(file_path2, sheet_name='Body part and Mod to SubS')\n",
        "\n",
        "# Create a dictionary to map (body part, modality) pairs to subspecialty values\n",
        "\n",
        "sub_dict = {}\n",
        "for index, row in df_excel.iterrows():\n",
        "    subspecialty = row['Subspecialty']\n",
        "    body_part = row['Body part new']\n",
        "    modality = row['Modality']\n",
        "    key = (modality, body_part)\n",
        "    sub_dict[key] = subspecialty\n",
        "\n",
        "# Create 'subspecialty_new' column based on 'body part' and 'modality'\n",
        "sub_dict = {}\n",
        "for index, row in df_excel.iterrows():\n",
        "    subspecialty = row['Subspecialty']\n",
        "    body_part = row['Body part new']\n",
        "    modality = row['Modality']\n",
        "    key = (modality.lower(), body_part.lower())\n",
        "    sub_dict[key] = subspecialty\n",
        "\n",
        "# Create 'subspecialty_new' column based on 'body part' and 'modality'\n",
        "subspecialty_list = []\n",
        "for index, row in df.iterrows():\n",
        "    body_part = row['Body Part'].lower()\n",
        "    modality = row['Modality'].lower()\n",
        "    # Look for a matching (modality, body part) pair in the sub_dict\n",
        "    key = (modality, body_part)\n",
        "    if key in sub_dict:\n",
        "        subspecialty_list.append(sub_dict[key])\n",
        "    else:\n",
        "        # If no exact match is found, try to find a match for any body part that contains the given body part substring\n",
        "        possible_keys = [k for k in sub_dict.keys() if modality == k[0].lower() and body_part in k[1].lower()]\n",
        "        if len(possible_keys) > 0:\n",
        "            subspecialty_list.append(sub_dict[possible_keys[0]])\n",
        "        else:\n",
        "            subspecialty_list.append('unknown')\n",
        "\n",
        "df['Subspecialty'] = subspecialty_list\n",
        "df['Subspecialty']=df['Subspecialty'].str.lower()\n",
        "\n",
        "# Print the updated DataFrame with the new 'subspecialty' column\n",
        "df\n",
        "print(df['Subspecialty'].value_counts()['unknown'])\n",
        "print(df['Subspecialty'].unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EivRJdSWXdVT"
      },
      "outputs": [],
      "source": [
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualizations**"
      ],
      "metadata": {
        "id": "5rZL66xWR3eu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jb7_P49tvJ_Q"
      },
      "outputs": [],
      "source": [
        "# Visualize the Subspecialty column\n",
        "df['Subspecialty'].value_counts().plot(kind='bar')\n",
        "plt.title(\"Distribution of Subspecialty\")\n",
        "plt.xlabel(\"Subspecialty\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the Modality column\n",
        "df['Modality'].value_counts().plot(kind='bar')\n",
        "plt.title(\"Distribution of Modality\")\n",
        "plt.xlabel(\"Modality\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2W4WyCviNP3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the priority column\n",
        "df['Priority'].value_counts().plot(kind='bar')\n",
        "plt.title(\"Distribution of Priority\")\n",
        "plt.xlabel(\"Priority\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZMS4WmwUOf4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfCY7QFPvsWa"
      },
      "outputs": [],
      "source": [
        "# Visualize the priority column by Subspecialty\n",
        "plt.figure(figsize=(10, 6))  # Adjust the figure size\n",
        "# Group the data by 'Priority' and 'Subspecialty' columns and calculate the normalized value counts\n",
        "grouped = df.groupby(['Priority'])['Subspecialty'].value_counts(normalize=True).unstack()\n",
        "grouped.plot(kind='bar', cmap='tab20b')\n",
        "plt.title('Priority by Subspecialty')\n",
        "plt.xlabel('Priority')\n",
        "plt.ylabel('%')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title='Subspecialty')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the Patient Class column\n",
        "df['Patient Class'].value_counts().plot(kind='bar')\n",
        "plt.title(\"Distribution of Patient Class\")\n",
        "plt.xlabel(\"Patient Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p4tO-v3gTVGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the Patient Class column by Subspecialty\n",
        "plt.figure(figsize=(10, 6))  # Adjust the figure size\n",
        "# Group the data by 'Priority' and 'Subspecialty' columns and calculate the normalized value counts\n",
        "grouped = df.groupby(['Patient Class'])['Subspecialty'].value_counts(normalize=True).unstack()\n",
        "grouped.plot(kind='bar', cmap='tab20b')\n",
        "plt.title('Patient Class by Subspecialty')\n",
        "plt.xlabel('Patient Class')\n",
        "plt.ylabel('%')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title='Subspecialty')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DmtF3QOqVqGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the Patient Class column by Modality\n",
        "plt.figure(figsize=(10, 6))  # Adjust the figure size\n",
        "# Group the data by 'Priority' and 'Subspecialty' columns and calculate the normalized value counts\n",
        "grouped = df.groupby(['Patient Class'])['Modality'].value_counts(normalize=True).unstack()\n",
        "grouped.plot(kind='bar', cmap='tab20b')\n",
        "plt.title('Patient Class by Modality')\n",
        "plt.xlabel('Patient Class')\n",
        "plt.ylabel('%')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title='Modality')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jhCcnYZ-WNou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1D7tyxc0wpkc"
      },
      "outputs": [],
      "source": [
        "#Visualising the priority column in division to subspecialties and customers\n",
        "grouped = df.groupby(['Tenant DESC', 'Priority'])['Subspecialty'].value_counts().unstack().plot(kind='bar')\n",
        "plt.title('Priority by Subspecialty')\n",
        "plt.xlabel('Priority')\n",
        "plt.ylabel('Count')\n",
        "# Move the legend outside the graph\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.figure(figsize=(10, 10))  # Adjust the figure size if desired\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the Body part column\n",
        "plt.figure(figsize=(10, 9))\n",
        "df['Body Part'].value_counts().plot(kind='bar')\n",
        "plt.title(\"Distribution of Body part\")\n",
        "plt.xlabel(\"Body part\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "icFKIR-sPM-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZjVYsKdXHu1"
      },
      "outputs": [],
      "source": [
        "#Visualising the priority column in division to customers\n",
        "grouped = df.groupby(['Priority'])['Tenant DESC'].value_counts().unstack().plot(kind='bar')\n",
        "plt.title('Priority by Tenant DESC')\n",
        "plt.xlabel('Priority')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULc8O-Qsw2Yl"
      },
      "outputs": [],
      "source": [
        "# Visualize the Patient Class column by Priority\n",
        "plt.figure(figsize=(10, 6))  # Adjust the figure size\n",
        "# Group the data by 'Patient Class' and 'Priority' columns and calculate the normalized value counts\n",
        "grouped = df.groupby(['Patient Class'])['Priority'].value_counts(normalize=True).unstack()\n",
        "grouped.plot(kind='bar', cmap='tab20b')\n",
        "plt.title('Patient Class by Priority')\n",
        "plt.xlabel('Patient Class')\n",
        "plt.ylabel('%')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title='Priority')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8UoT9FMx3b6"
      },
      "outputs": [],
      "source": [
        "#Visualize the 'Patient Class' column in division to customer\n",
        "grouped = df.groupby(['Patient Class'])['Tenant DESC'].value_counts().unstack().plot(kind='bar')\n",
        "plt.title('Patient Class by Tenant DESC')\n",
        "plt.xlabel('Patient Class')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnUkGBuiufzw"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMV3F-GSjWTq"
      },
      "outputs": [],
      "source": [
        "df['Exam Description'] = df['Exam Description'].str.lower()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dealing with Missing Values**"
      ],
      "metadata": {
        "id": "dXUEHNtjSCjP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohGvOqDuZuw8"
      },
      "outputs": [],
      "source": [
        "df['Patient Class']=df['Patient Class'].fillna('unknown')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jgBMnxHvaqE"
      },
      "outputs": [],
      "source": [
        "df['Patient Class'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reduction of missing values**"
      ],
      "metadata": {
        "id": "Dvub7VFOSPxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update of 'Patient Class' column to 'outpatient' for rows where the 'Patient Class' is 'unknown' and the 'Modality' is 'mg'\n",
        "for index, row in df.iterrows():\n",
        "  if row['Patient Class'] == 'unknown' and row['Modality'] == 'mg':\n",
        "    df.at[index, 'Patient Class'] ='outpatient'\n",
        "print (df['Patient Class'].value_counts())"
      ],
      "metadata": {
        "id": "os9QZp_6UYHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFbxs-tWyEB7"
      },
      "outputs": [],
      "source": [
        "# Update of 'Patient Class' value to 'outpatient' if the word 'outside' is present in the column Exam Description\n",
        "for index, row in df.iterrows():\n",
        "    words = row['Exam Description'].split()\n",
        "    if \"outside\" in words:\n",
        "        df.at[index, 'Patient Class'] = 'outpatient'\n",
        "\n",
        "print(df['Patient Class'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creation of target variable- Urgency score**"
      ],
      "metadata": {
        "id": "eOX1SowHSbNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Avera_Urgency'] = np.nan"
      ],
      "metadata": {
        "id": "sDiL4iDujCXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imS7IbQiqdks"
      },
      "outputs": [],
      "source": [
        "#create urgency score according to \"Avera\" rules, for all subjects\n",
        "\n",
        "def get_urgency_score(df):\n",
        "    \"\"\"\n",
        "    Calculates the urgency score based on priority and exam description for each record in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "        df (pandas.DataFrame): The input DataFrame containing columns 'Priority', 'Patient Class', and 'Exam Description'.\n",
        "\n",
        "    Returns:\n",
        "        pandas.Series: The urgency scores as a Series.\n",
        "\n",
        "    Urgency Score Calculation:\n",
        "        - For 'outpatient' cases:\n",
        "            - Priority 1: 22\n",
        "            - Priority 2: 46\n",
        "            - Priority 3: 58\n",
        "        - For 'inpatient' cases:\n",
        "            - Priority 1: 26\n",
        "            - Priority 2: 42\n",
        "            - Priority 3: 54\n",
        "        - For 'emergency' cases: 10\n",
        "        - If the exam description contains any of the keywords in the 'Exam_Desc' list (case-insensitive):\n",
        "            - Urgency score is set to 1.\n",
        "    \"\"\"\n",
        "    Exam_Desc = ['head', 'brain', 'stroke']\n",
        "    df['Avera_Urgency'] = None  # initialize the column with None values\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "          exam_desc = row['Exam Description']\n",
        "          if row['Patient Class'] == 'outpatient':\n",
        "              if row['Priority'] == 1:\n",
        "                  df.loc[index, 'Avera_Urgency'] = 22\n",
        "              elif row['Priority'] == 2:\n",
        "                  df.loc[index, 'Avera_Urgency'] = 46\n",
        "              elif row['Priority'] == 3:\n",
        "                  df.loc[index, 'Avera_Urgency'] = 58\n",
        "          elif row['Patient Class'] == 'inpatient':\n",
        "              if row['Priority'] == 1:\n",
        "                  df.loc[index, 'Avera_Urgency'] = 26\n",
        "              elif row['Priority'] == 2:\n",
        "                  df.loc[index, 'Avera_Urgency'] = 42\n",
        "              elif row['Priority'] == 3:\n",
        "                  df.loc[index, 'Avera_Urgency'] = 54\n",
        "          elif row['Patient Class'] == 'emergency':\n",
        "            df.loc[index, 'Avera_Urgency'] = 10\n",
        "\n",
        "            # Check if any part of the values in 'Exam_Desc' list appears in the exam description\n",
        "            if any((keyword.lower() in exam_desc.lower()) for keyword in Exam_Desc):\n",
        "                df.at[index, 'Avera_Urgency'] = 1\n",
        "\n",
        "    return df['Avera_Urgency']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-k4VsIJJr_if"
      },
      "outputs": [],
      "source": [
        "df['Avera_Urgency'] = get_urgency_score(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a01Iig-MS-KV"
      },
      "outputs": [],
      "source": [
        "# replace NaN values with 0 in Avera_Urgency column\n",
        "df['Avera_Urgency']=df['Avera_Urgency'].fillna(0).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bR9uFUcsJfA"
      },
      "outputs": [],
      "source": [
        "df['Avera_Urgency'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Atlantic_Urgency'] = np.nan"
      ],
      "metadata": {
        "id": "8vjdlWo3t_V8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNShbEo_sKQS"
      },
      "outputs": [],
      "source": [
        "#create urgency score according to \"Atlantic\" rules, for all subjects\n",
        "\n",
        "def get_urgency_score2(df):\n",
        "    \"\"\"\n",
        "    Calculates the urgency score based on priority, patient class, modality, and exam description for each record in a DataFrame,\n",
        "    following the 'Atlantic' rules.\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas.DataFrame): The input DataFrame containing columns 'Priority', 'Patient Class', 'Modality', and 'Exam Description'.\n",
        "\n",
        "    Returns:\n",
        "    pandas.Series: The urgency scores as a Series.\n",
        "\n",
        "    Urgency Score Calculation:\n",
        "        - For 'outpatient' cases:\n",
        "            - Priority 1: 40\n",
        "            - Priority 3: 90\n",
        "        - For 'inpatient' cases:\n",
        "            - Priority 1: 40\n",
        "            - Priority 2: 50\n",
        "            - Priority 3: 60\n",
        "        - For 'emergency' cases: 30\n",
        "        - If 'mg' is present in the modality: 91\n",
        "        - If 'stroke' is present in the exam description (case-insensitive): 1\n",
        "    \"\"\"\n",
        "    df['Atlantic_Urgency'] = None  # initialize the column with None values\n",
        "    pattern = r'\\bstroke\\b'\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        if row['Patient Class'] == 'outpatient':\n",
        "          if row['Priority'] == 1:\n",
        "            df.loc[index, 'Atlantic_Urgency'] = 40\n",
        "          elif row['Priority'] == 3:\n",
        "            df.loc[index, 'Atlantic_Urgency'] = 90\n",
        "        elif row['Patient Class'] == 'inpatient':\n",
        "          if row['Priority'] == 1:\n",
        "            df.loc[index, 'Atlantic_Urgency'] = 40\n",
        "          elif row['Priority'] == 2:\n",
        "            df.loc[index, 'Atlantic_Urgency'] = 50\n",
        "          elif row['Priority'] == 3:\n",
        "            df.loc[index, 'Atlantic_Urgency'] = 60\n",
        "        elif row['Patient Class'] == 'emergency':\n",
        "          df.loc[index, 'Atlantic_Urgency'] = 30\n",
        "        elif 'mg' in row['Modality']:\n",
        "          df.loc[index, 'Atlantic_Urgency'] = 91\n",
        "        if pd.Series(row['Exam Description']).str.contains('stroke', case=False).any():\n",
        "          df.loc[index, 'Atlantic_Urgency'] = 1\n",
        "    return df['Atlantic_Urgency']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkU5ljsZtA6c"
      },
      "outputs": [],
      "source": [
        "df['Atlantic_Urgency'] = get_urgency_score2(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# replace NaN values with 0 in Atlantic_Urgency column\n",
        "df['Atlantic_Urgency']=df['Atlantic_Urgency'].fillna(0).astype(int)"
      ],
      "metadata": {
        "id": "-YgSiIUkupOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vzc9HdPtH-I"
      },
      "outputs": [],
      "source": [
        "df['Atlantic_Urgency'].value_counts(dropna=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BeIduP-kRVU"
      },
      "outputs": [],
      "source": [
        "# Creating a new column of \"Average_Urgency\" based on Avera&Atlantic urgency, exsept for the mentioned scores.\n",
        "\n",
        "scores = [0, 1, 20, 91]\n",
        "\n",
        "def create_average(df):\n",
        "    \"\"\"\n",
        "    Creates a new column 'Average_Urgency' in the DataFrame based on the 'Atlantic_Urgency' and 'Avera_Urgency' columns,\n",
        "    excluding the mentioned scores.\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas.DataFrame): The input DataFrame containing columns 'Atlantic_Urgency' and 'Avera_Urgency'.\n",
        "\n",
        "    Returns:\n",
        "     pandas.Series: The average urgency scores as a Series.\n",
        "\n",
        "    Average Urgency Calculation:\n",
        "        - If both 'Atlantic_Urgency' and 'Avera_Urgency' are not in the scores list:\n",
        "            - The average urgency is calculated as the mean of 'Atlantic_Urgency' and 'Avera_Urgency' (skipping NaN values).\n",
        "        - If either 'Atlantic_Urgency' or 'Avera_Urgency' is present in the scores list:\n",
        "            - The average urgency is set to the corresponding score from the scores list.\n",
        "        - The mentioned scores [0, 1, 20, 91] are excluded from the average calculation.\n",
        "    \"\"\"\n",
        "    df['Average_Urgency'] = None\n",
        "    for index, row in df.iterrows():\n",
        "        atlantic = row['Atlantic_Urgency']\n",
        "        avera = row['Avera_Urgency']\n",
        "        if all(num not in [atlantic, avera] for num in scores):\n",
        "            avg_urgency = pd.Series([atlantic, avera]).mean(skipna=True)\n",
        "            df.loc[index, 'Average_Urgency'] = avg_urgency\n",
        "        else:\n",
        "            for num in scores:\n",
        "                if num in [atlantic, avera]:\n",
        "                    df.loc[index, 'Average_Urgency'] = num\n",
        "                    break\n",
        "\n",
        "    return df['Average_Urgency']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaMntlEz4976"
      },
      "outputs": [],
      "source": [
        "df['Average_Urgency'] = create_average(df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Average_Urgency'] = df['Average_Urgency'].astype(int)"
      ],
      "metadata": {
        "id": "KyCieoG50ZjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdUs4zTb_2v6"
      },
      "outputs": [],
      "source": [
        "df['Average_Urgency'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0J3I4wS_lonM"
      },
      "outputs": [],
      "source": [
        "df['Average_Urgency'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SEaDvZfFTuM"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZ0o2f2AZ-cY"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"Avera & Atlantic Data.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}